{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6f1854",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-07T18:43:22.310627Z",
     "iopub.status.busy": "2024-12-07T18:43:22.310178Z",
     "iopub.status.idle": "2024-12-07T18:43:56.723495Z",
     "shell.execute_reply": "2024-12-07T18:43:56.721978Z"
    },
    "papermill": {
     "duration": 34.421493,
     "end_time": "2024-12-07T18:43:56.726038",
     "exception": false,
     "start_time": "2024-12-07T18:43:22.304545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 31.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q \"google-generativeai>=0.8.3\" chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e3f26",
   "metadata": {
    "papermill": {
     "duration": 0.003356,
     "end_time": "2024-12-07T18:43:56.733447",
     "exception": false,
     "start_time": "2024-12-07T18:43:56.730091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Obtain your API Key from Google AI Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b04492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T18:43:56.742299Z",
     "iopub.status.busy": "2024-12-07T18:43:56.741927Z",
     "iopub.status.idle": "2024-12-07T18:43:57.931803Z",
     "shell.execute_reply": "2024-12-07T18:43:57.930733Z"
    },
    "papermill": {
     "duration": 1.197419,
     "end_time": "2024-12-07T18:43:57.934418",
     "exception": false,
     "start_time": "2024-12-07T18:43:56.736999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9cf5381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T18:43:57.944072Z",
     "iopub.status.busy": "2024-12-07T18:43:57.943428Z",
     "iopub.status.idle": "2024-12-07T18:43:58.783102Z",
     "shell.execute_reply": "2024-12-07T18:43:58.781937Z"
    },
    "papermill": {
     "duration": 0.847211,
     "end_time": "2024-12-07T18:43:58.785544",
     "exception": false,
     "start_time": "2024-12-07T18:43:57.938333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "GOOGLE_GEMINI_API_KEY = user_secrets.get_secret(\"GOOGLE_GEMINI_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd532a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T18:43:58.795120Z",
     "iopub.status.busy": "2024-12-07T18:43:58.794727Z",
     "iopub.status.idle": "2024-12-07T18:43:59.770465Z",
     "shell.execute_reply": "2024-12-07T18:43:59.769127Z"
    },
    "papermill": {
     "duration": 0.983275,
     "end_time": "2024-12-07T18:43:59.772790",
     "exception": false,
     "start_time": "2024-12-07T18:43:58.789515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n"
     ]
    }
   ],
   "source": [
    "# Checking Available Embedding Models supported by Google\n",
    "for m in genai.list_models():\n",
    "    if \"embedContent\" in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706af2e",
   "metadata": {
    "papermill": {
     "duration": 0.003594,
     "end_time": "2024-12-07T18:43:59.780401",
     "exception": false,
     "start_time": "2024-12-07T18:43:59.776807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating Embedding Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1853375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T18:43:59.791347Z",
     "iopub.status.busy": "2024-12-07T18:43:59.790744Z",
     "iopub.status.idle": "2024-12-07T18:43:59.798657Z",
     "shell.execute_reply": "2024-12-07T18:43:59.797347Z"
    },
    "papermill": {
     "duration": 0.015662,
     "end_time": "2024-12-07T18:43:59.801129",
     "exception": false,
     "start_time": "2024-12-07T18:43:59.785467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding Documents for creating Embedding Database\n",
    "DOCUMENT1 = \"Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans using natural language. The ultimate goal of NLP is to enable machines to understand, interpret, and generate human language in a way that is both meaningful and useful. NLP combines computational linguistics, machine learning, and deep learning to process and analyze large amounts of natural language data\"\n",
    "DOCUMENT2 = \"Tokenization is one of the first steps in preprocessing text for natural language processing tasks. It involves splitting a string of text into individual words or tokens. Tokenization is a crucial step for text analysis as it enables algorithms to handle smaller, more manageable chunks of text. There are different approaches to tokenization, including word-level tokenization and sentence-level tokenization.\"\n",
    "DOCUMENT3 = \"Named Entity Recognition (NER) is a key NLP task that involves identifying and classifying entities in text into predefined categories such as names of people, organizations, locations, dates, and more. NER is useful in many applications, including information extraction, question answering, and content summarization. Advanced techniques like deep learning and transformers have significantly improved the performance of NER systems.\"\n",
    "DOCUMENT4 = \"Sentiment analysis is a process of determining the emotional tone behind a series of words, used to understand the attitude or opinion expressed in text. It's widely applied in customer service, marketing, and social media analysis. Sentiment analysis typically involves classifying text as positive, negative, or neutral. Techniques such as supervised learning, lexicon-based methods, and deep learning are commonly employed for sentiment classification.\"\n",
    "DOCUMENT5 = \"Part-of-speech (POS) tagging is a process in which each word in a sentence is labeled with its corresponding part of speech (e.g., noun, verb, adjective). POS tagging is essential for many NLP applications, such as syntactic parsing, information extraction, and machine translation. Common methods for POS tagging include rule-based, statistical, and machine learning-based approaches.\"\n",
    "DOCUMENT6 = \"Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation. Unlike traditional one-hot encoding, word embeddings use dense vectors of real numbers that capture semantic relationships between words. Popular word embedding models include Word2Vec, GloVe, and FastText, all of which are used to learn word representations from large text corpora.\"\n",
    "DOCUMENT7 = \"Transformers are a type of neural network architecture that has revolutionized the field of NLP. Unlike traditional recurrent neural networks (RNNs), transformers use self-attention mechanisms to process words in parallel rather than sequentially. This architecture is highly effective for tasks such as machine translation, text generation, and question answering. Prominent transformer models include BERT, GPT, and T5\"\n",
    "DOCUMENT8 = \"Machine translation (MT) is the task of automatically converting text from one language to another. Early MT systems relied on rule-based methods, but modern systems use statistical and neural machine translation techniques. Neural machine translation (NMT) is based on deep learning models, particularly sequence-to-sequence architectures, and has significantly improved the quality of automatic translations.\"\n",
    "DOCUMENT9 = \"Text classification is the task of categorizing text into predefined labels or classes. It's widely used for applications such as spam detection, topic modeling, and sentiment analysis. Common techniques for text classification include Naive Bayes, support vector machines (SVM), and deep learning methods. The goal is to build a model that can automatically assign labels to unseen text based on patterns learned from labeled data.\"\n",
    "DOCUMENT10 = \"Question answering (QA) systems aim to answer questions posed in natural language. QA systems can be categorized into two types: extractive and abstractive. Extractive QA systems retrieve answers directly from a given text, while abstractive QA systems generate new answers based on their understanding of the text. Recent advancements in QA systems have been driven by deep learning techniques, particularly transformer-based models like BERT and T5\"\n",
    "\n",
    "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3, DOCUMENT4, DOCUMENT5, DOCUMENT6, DOCUMENT7, DOCUMENT8,\n",
    "            DOCUMENT9, DOCUMENT10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "797ef5ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T18:43:59.811177Z",
     "iopub.status.busy": "2024-12-07T18:43:59.810321Z",
     "iopub.status.idle": "2024-12-07T18:44:00.972917Z",
     "shell.execute_reply": "2024-12-07T18:44:00.971863Z"
    },
    "papermill": {
     "duration": 1.170221,
     "end_time": "2024-12-07T18:44:00.975413",
     "exception": false,
     "start_time": "2024-12-07T18:43:59.805192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specifiying to generate embeddings for document or queries\n",
    "    document_mode = True\n",
    "    def __call__(self, input):\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "\n",
    "        retry_policy = {\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n",
    "        response = genai.embed_content(\n",
    "            model = \"models/text-embedding-004\",\n",
    "            content = input,\n",
    "            task_type = embedding_task,\n",
    "            request_options = retry_policy\n",
    "        )\n",
    "        # print(\"response: \", response)\n",
    "        return response[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "405f43a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T18:44:00.984923Z",
     "iopub.status.busy": "2024-12-07T18:44:00.984512Z",
     "iopub.status.idle": "2024-12-07T18:44:02.560370Z",
     "shell.execute_reply": "2024-12-07T18:44:02.559142Z"
    },
    "papermill": {
     "duration": 1.583733,
     "end_time": "2024-12-07T18:44:02.563055",
     "exception": false,
     "start_time": "2024-12-07T18:44:00.979322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "DB_NAME = \"informationonnlp\"\n",
    "embed_fun = GeminiEmbeddingFunction()\n",
    "embed_fun.document_mode = True\n",
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.get_or_create_collection(name = DB_NAME, embedding_function = embed_fun)\n",
    "db.add(documents = documents, ids = [str(i) for i in range(len(documents))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d4fafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T18:44:02.572338Z",
     "iopub.status.busy": "2024-12-07T18:44:02.571931Z",
     "iopub.status.idle": "2024-12-07T18:44:02.591729Z",
     "shell.execute_reply": "2024-12-07T18:44:02.590553Z"
    },
    "papermill": {
     "duration": 0.028336,
     "end_time": "2024-12-07T18:44:02.595179",
     "exception": false,
     "start_time": "2024-12-07T18:44:02.566843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Documents in DB:  10\n",
      "The First Documents is:  {'ids': ['0'], 'embeddings': array([[-4.71840911e-02,  2.97533516e-02, -1.76581424e-02,\n",
      "        -9.62279737e-03, -3.14820074e-02,  4.40917425e-02,\n",
      "         2.00140141e-02,  3.33735719e-02, -3.76888039e-03,\n",
      "        -2.50776000e-02, -4.44155633e-02, -4.27163253e-03,\n",
      "         7.05401003e-02,  7.13116955e-03,  4.92972136e-02,\n",
      "        -5.22420779e-02,  3.71682532e-02,  4.91188951e-02,\n",
      "        -1.16843678e-01,  3.05019207e-02,  2.45447713e-03,\n",
      "        -3.36538292e-02,  1.00485270e-03, -5.13570383e-02,\n",
      "        -4.45667142e-03,  1.80294793e-02,  1.89410988e-02,\n",
      "         8.93730577e-03, -3.79313540e-04, -2.77177542e-02,\n",
      "         5.55811040e-02,  5.23680449e-02,  2.86156517e-02,\n",
      "        -7.42548555e-02, -1.83122158e-02, -2.06953194e-02,\n",
      "         1.93992481e-02, -1.21836467e-02,  6.18599579e-02,\n",
      "        -4.01744843e-02, -4.15999554e-02, -2.03616992e-02,\n",
      "        -6.36188909e-02,  5.02354205e-02, -4.20208760e-02,\n",
      "         1.54954158e-02, -6.61541009e-03,  7.69082829e-02,\n",
      "        -7.47932494e-02,  7.99836218e-02, -2.26962063e-02,\n",
      "        -1.71495415e-02, -4.01727930e-02,  5.67777343e-02,\n",
      "        -4.71234508e-02, -2.80216578e-02, -1.33416150e-02,\n",
      "        -7.64565961e-03, -1.26540335e-02, -2.72021387e-02,\n",
      "        -4.35299166e-02, -1.94471851e-02, -1.20509705e-02,\n",
      "        -2.12471616e-02, -3.93117629e-02, -7.66066427e-04,\n",
      "        -2.37472858e-02, -2.59977430e-02, -6.04303554e-02,\n",
      "         8.08137190e-03,  3.23861837e-02,  4.31353748e-02,\n",
      "        -4.43262719e-02,  3.56946476e-02, -3.47025767e-02,\n",
      "        -8.34630802e-03,  1.75196808e-02, -2.56110914e-02,\n",
      "        -2.33467445e-02, -2.55578873e-03, -2.92216521e-02,\n",
      "         5.25379507e-03,  5.86849488e-02,  5.85604832e-02,\n",
      "        -3.33421454e-02, -3.00769340e-02, -2.14661621e-02,\n",
      "        -3.98827270e-02, -7.01995492e-02, -2.96817422e-02,\n",
      "         4.97612245e-02, -1.56740323e-02, -3.39460671e-02,\n",
      "        -1.84138375e-03,  6.24698475e-02, -3.38550610e-03,\n",
      "        -2.07102764e-02, -6.17689043e-02,  9.23889950e-02,\n",
      "         4.54460979e-02, -8.33674427e-03,  1.13387965e-02,\n",
      "        -3.22590815e-03, -2.80925669e-02, -1.24261742e-02,\n",
      "         1.08157121e-01,  6.17317669e-02, -5.02029508e-02,\n",
      "        -2.46698968e-02,  4.19448875e-02,  1.79914404e-02,\n",
      "         1.54979818e-03, -8.49046651e-03, -4.43053581e-02,\n",
      "        -1.22590512e-02,  1.48679316e-03, -5.36361933e-02,\n",
      "         1.93656106e-02, -3.25267240e-02,  1.33937057e-02,\n",
      "        -8.90749693e-03,  6.76925406e-02,  2.42606234e-02,\n",
      "         2.01289803e-02,  3.66047062e-02, -1.43670598e-02,\n",
      "         3.47711854e-02, -4.40865904e-02, -2.86904760e-02,\n",
      "        -2.62030568e-02,  1.77866265e-01, -5.55924326e-02,\n",
      "        -1.39307249e-02,  3.83653902e-02, -6.04968667e-02,\n",
      "         2.50682957e-03,  4.60764021e-02, -2.09928583e-03,\n",
      "        -4.50437143e-03,  6.65638000e-02, -1.77875608e-02,\n",
      "        -3.24861668e-02, -4.96201888e-02,  2.46641450e-02,\n",
      "         7.54671404e-03, -4.72039692e-02,  1.67604648e-02,\n",
      "        -2.30504130e-03, -2.49178745e-02, -2.07253378e-02,\n",
      "         3.18591017e-03,  2.82032765e-03,  5.35738021e-02,\n",
      "         1.91583708e-02, -3.30597237e-02, -6.89145271e-03,\n",
      "         4.99716215e-02,  6.86105993e-03,  3.76817659e-02,\n",
      "        -1.75236929e-02,  3.85608673e-02, -3.90959419e-02,\n",
      "         1.72898006e-02, -4.77221757e-02, -3.77517417e-02,\n",
      "        -1.87819041e-02,  2.39186808e-02, -3.17591652e-02,\n",
      "        -3.50611284e-02,  5.48673375e-03, -1.68833844e-02,\n",
      "         1.55477114e-02,  5.39644714e-03, -8.00044164e-02,\n",
      "         1.92996822e-02,  1.36546697e-02, -1.95175521e-02,\n",
      "        -4.15746905e-02, -2.45788391e-03,  1.55140515e-02,\n",
      "         8.20366070e-02,  3.96890491e-02, -1.96686145e-02,\n",
      "        -6.20880462e-02,  4.92333621e-03, -2.37341058e-02,\n",
      "        -3.22368857e-03,  3.17193754e-02,  6.45606071e-02,\n",
      "         4.37879041e-02,  1.04045970e-02, -2.51493100e-02,\n",
      "         3.85445096e-02, -2.72476580e-03,  2.16879100e-02,\n",
      "        -2.29004398e-02,  3.08124367e-02, -6.99967816e-02,\n",
      "        -8.26016068e-03, -7.41944984e-02,  2.01124754e-02,\n",
      "        -2.76686344e-02,  3.80947702e-02, -1.50731094e-02,\n",
      "        -3.98936728e-03, -1.30058974e-02,  1.09376563e-02,\n",
      "        -1.86951030e-02,  1.52934846e-02,  1.78456046e-02,\n",
      "        -3.82380560e-02, -5.11633754e-02, -1.24639822e-02,\n",
      "        -6.30725324e-02, -1.68230310e-02, -1.31859137e-02,\n",
      "         8.60695243e-02,  8.69826414e-03,  8.35348070e-02,\n",
      "        -1.79419927e-02, -7.82756880e-03, -5.13192415e-02,\n",
      "        -2.60511022e-02,  2.25708298e-02,  8.77822414e-02,\n",
      "         2.77834870e-02, -3.86017039e-02, -2.85147261e-02,\n",
      "         3.41770798e-02, -3.25750597e-02, -2.53542355e-04,\n",
      "         3.89304757e-03,  1.15568163e-02, -6.27971115e-03,\n",
      "         3.37634608e-02,  6.99603325e-03, -3.99050340e-02,\n",
      "        -2.20977771e-03, -4.14723195e-02,  2.09018588e-02,\n",
      "        -4.65046475e-03,  2.65098661e-02,  4.07773182e-02,\n",
      "        -2.92039406e-03,  4.37676236e-02,  1.16375061e-02,\n",
      "        -7.35882437e-03, -1.35445157e-02, -3.83458287e-02,\n",
      "        -3.70004699e-02,  4.61812504e-02, -4.82678786e-02,\n",
      "        -2.44068652e-02, -5.13478182e-02, -4.33542691e-02,\n",
      "        -2.68470384e-02,  3.92501755e-03, -6.73535140e-03,\n",
      "        -1.85282622e-02, -7.40181003e-03,  4.93555777e-02,\n",
      "        -2.74591651e-02, -2.91231778e-02, -7.31861815e-02,\n",
      "         1.27106849e-02, -8.22304040e-02, -4.62421626e-02,\n",
      "        -4.03740481e-02,  1.77457202e-02, -2.70543359e-02,\n",
      "         4.70208675e-02, -1.71794947e-02, -4.39186255e-03,\n",
      "        -3.37842964e-02, -4.29226924e-03,  2.75654532e-02,\n",
      "        -1.96569669e-03,  1.39600169e-02, -4.94830385e-02,\n",
      "        -2.21868549e-02,  5.10918982e-02,  2.35994952e-03,\n",
      "         1.13736996e-02, -4.41260934e-02,  3.63288000e-02,\n",
      "         1.73333427e-03,  2.35914178e-02,  1.46418065e-02,\n",
      "        -3.18489149e-02, -3.13593745e-02,  3.72378789e-02,\n",
      "         3.22043039e-02, -7.30563551e-02, -5.41960485e-02,\n",
      "         3.90374064e-02,  9.17598978e-03,  3.96485329e-02,\n",
      "         4.34122905e-02, -3.62981134e-03,  3.17053124e-02,\n",
      "        -1.49302436e-02,  4.23468873e-02, -1.93960052e-02,\n",
      "         4.03612107e-02,  2.86429785e-02,  2.76615284e-02,\n",
      "         1.58147942e-02, -3.34852301e-02, -1.79111566e-02,\n",
      "         7.50375018e-02,  1.17395900e-03, -3.90129839e-03,\n",
      "        -2.11556535e-02, -3.69513817e-02, -3.19452994e-02,\n",
      "        -5.87043958e-03, -1.95201293e-01,  4.14586514e-02,\n",
      "        -5.51545843e-02, -2.66707800e-02,  1.24888606e-02,\n",
      "         2.63296086e-02, -2.49532494e-03, -5.84572665e-02,\n",
      "         3.81386280e-02, -2.78858598e-02,  1.39071187e-02,\n",
      "         1.85545813e-02,  2.25612186e-02, -1.17089751e-03,\n",
      "         2.08857991e-02, -1.31651517e-02, -1.87326744e-02,\n",
      "        -4.76150066e-02, -2.79750284e-02, -5.76781742e-02,\n",
      "        -1.19305197e-02,  4.95958291e-02,  5.39406464e-02,\n",
      "         3.98548059e-02,  1.18325585e-02,  1.89784769e-04,\n",
      "         3.50674130e-02,  7.91554078e-02, -3.45612168e-02,\n",
      "         3.33876349e-02, -3.76974745e-03, -3.41651700e-02,\n",
      "         1.27423396e-02, -4.06712294e-02,  2.61775460e-02,\n",
      "         5.73873036e-02,  5.49457520e-02, -2.09158733e-02,\n",
      "        -9.59753618e-03, -1.62182041e-02,  3.68621200e-02,\n",
      "        -1.08083254e-02,  5.50846523e-03, -4.73249936e-03,\n",
      "         1.09484373e-02,  1.29447188e-02,  3.48251918e-03,\n",
      "         1.30600380e-02, -1.71079976e-03, -4.10293043e-03,\n",
      "        -4.05051708e-02,  2.06438377e-02, -9.65714362e-03,\n",
      "         8.86187050e-03,  5.47537301e-03,  3.85563448e-02,\n",
      "         5.69976959e-03, -3.13373841e-03,  1.32498685e-02,\n",
      "        -4.64663245e-02,  3.80284298e-04,  4.52747941e-02,\n",
      "         3.20772752e-02,  9.59369261e-03, -3.73560674e-02,\n",
      "        -6.27556518e-02, -2.06571817e-02, -1.08320815e-02,\n",
      "        -4.96394895e-02,  6.81361780e-02, -1.03196688e-02,\n",
      "        -5.88542335e-02,  5.57609554e-03,  3.46395001e-02,\n",
      "         1.74173675e-02,  9.50072054e-03,  1.27354693e-02,\n",
      "        -1.61731988e-02,  7.92893488e-03,  1.35506094e-02,\n",
      "        -8.86485912e-03, -1.08566117e-02, -1.30699119e-02,\n",
      "         1.96182840e-02,  5.04036583e-02,  9.93750244e-03,\n",
      "         4.86279950e-02, -7.17875659e-02, -3.29355076e-02,\n",
      "         2.45076288e-02,  3.08833849e-02,  2.13486105e-02,\n",
      "         2.34972853e-02, -1.36324279e-02, -1.60846878e-02,\n",
      "        -4.64621522e-02,  7.61847664e-03,  3.02407220e-02,\n",
      "        -1.09657506e-03,  9.50595643e-03,  3.35086919e-02,\n",
      "         1.56867821e-02, -9.16744862e-03,  9.43784118e-02,\n",
      "        -1.21131551e-03,  4.70045867e-04,  2.77496036e-02,\n",
      "        -1.99449025e-02,  9.36138351e-03, -3.53932716e-02,\n",
      "        -1.59684736e-02,  4.14380692e-02, -1.31771620e-02,\n",
      "         4.11120988e-02, -2.92640962e-02,  4.36418355e-02,\n",
      "         2.53477786e-03,  2.74493974e-02, -8.92277434e-03,\n",
      "         3.22732404e-02, -3.94478925e-02,  3.21243773e-03,\n",
      "        -5.51910885e-02,  1.23029063e-02, -1.37448199e-02,\n",
      "         6.76659588e-03,  2.11411286e-02,  1.01367012e-02,\n",
      "        -3.04759666e-02,  1.87355895e-02,  5.34233823e-02,\n",
      "         3.69325727e-02,  5.99980028e-03, -1.85710769e-02,\n",
      "         5.69894351e-03, -1.69878621e-02, -5.19943796e-02,\n",
      "        -5.08974828e-02, -4.40849066e-02,  1.68437231e-02,\n",
      "         3.44956517e-02,  9.12081730e-03, -1.81662533e-02,\n",
      "         3.58746313e-02, -3.85776348e-02, -1.15690250e-02,\n",
      "         4.99752462e-02,  1.58577152e-02, -3.29630896e-02,\n",
      "         1.92096587e-02,  4.83856499e-02,  1.97961889e-02,\n",
      "        -4.45663184e-02,  2.37845276e-02,  7.82537311e-02,\n",
      "        -2.24029832e-02,  4.19053808e-02, -3.87156126e-03,\n",
      "        -7.10855350e-02, -4.25558025e-03,  4.65574153e-02,\n",
      "         3.08647496e-03,  1.68718696e-02, -4.21153381e-02,\n",
      "         2.85870698e-03,  3.14752907e-02, -3.28800716e-02,\n",
      "         5.37961684e-02,  9.14112478e-02,  2.02198178e-02,\n",
      "        -2.83674765e-02,  6.42845919e-03,  1.01264846e-02,\n",
      "         4.87691425e-02, -5.68703450e-02,  1.94227733e-02,\n",
      "        -2.75394730e-02,  4.54780087e-03, -1.48551175e-02,\n",
      "         1.98686793e-02,  2.94288378e-02, -3.46061774e-02,\n",
      "        -2.12936266e-03,  5.20906635e-02,  4.92484495e-02,\n",
      "         1.34754297e-03, -5.15798759e-03, -4.38950919e-02,\n",
      "         8.22205190e-03,  2.92388648e-02, -6.23023175e-02,\n",
      "        -1.96859837e-02,  7.26282001e-02,  2.07449254e-02,\n",
      "         2.50268951e-02, -2.42599007e-02,  1.89941563e-02,\n",
      "         7.55048217e-03, -4.52189008e-03,  9.64481663e-03,\n",
      "        -3.48425843e-02,  4.40006256e-02, -4.09332803e-03,\n",
      "         2.91059706e-02, -3.49058583e-02, -3.31427269e-02,\n",
      "         1.20399455e-02, -8.93377641e-04, -1.91565640e-02,\n",
      "        -3.13058868e-02, -1.80813186e-02,  2.80965753e-02,\n",
      "         8.94486066e-03, -1.12695336e-01, -4.44922112e-02,\n",
      "         7.20529631e-02,  3.48959565e-02,  5.85343735e-03,\n",
      "        -2.30609849e-02,  1.03695337e-02,  4.18742262e-02,\n",
      "         2.76354626e-02,  3.64859067e-02, -3.27976048e-02,\n",
      "         2.03462262e-02, -2.83205453e-02,  1.20704472e-02,\n",
      "         4.04543653e-02,  3.58073823e-02, -3.03856898e-02,\n",
      "        -9.45435930e-03,  9.03754607e-02,  2.24611331e-02,\n",
      "         6.79364651e-02,  9.71581601e-03, -6.06635958e-02,\n",
      "         7.62606226e-03,  5.35846651e-02,  9.45598294e-04,\n",
      "         2.29162537e-02,  5.21490574e-02, -3.09925359e-02,\n",
      "        -2.83120517e-02, -1.66046582e-02,  1.31057827e-02,\n",
      "         1.67478770e-02,  1.65275484e-02, -2.27608345e-02,\n",
      "         5.28809279e-02,  2.46176552e-02, -3.10160685e-02,\n",
      "         1.65696740e-02, -7.83866551e-03,  1.24152815e-02,\n",
      "        -3.78672853e-02, -3.65881845e-02, -8.08349438e-03,\n",
      "        -1.32720461e-02, -2.69747451e-02, -6.30190177e-03,\n",
      "        -3.77186649e-02,  6.39418662e-02,  1.42001146e-02,\n",
      "        -3.50995511e-02, -4.42992710e-03, -5.33606578e-03,\n",
      "         1.63956434e-02, -4.12839558e-03,  2.89154910e-02,\n",
      "         1.76850241e-02, -1.27065666e-02,  5.29003935e-03,\n",
      "         1.93899369e-03, -3.15727107e-02, -1.79651193e-02,\n",
      "         2.75008809e-02, -4.55422886e-03, -6.72531500e-03,\n",
      "         9.53261089e-03,  2.35799085e-02, -8.03677291e-02,\n",
      "        -7.87237287e-03,  4.20063455e-03,  2.21134741e-02,\n",
      "         3.31462398e-02, -3.63730043e-02,  3.14492024e-02,\n",
      "         1.36539582e-02, -2.41002459e-02, -3.31615396e-02,\n",
      "        -5.37985414e-02, -1.72870848e-02, -1.35141546e-02,\n",
      "        -1.32448571e-02,  1.94927659e-02,  3.80282439e-02,\n",
      "        -6.05052151e-03,  1.62101332e-02, -9.97979715e-02,\n",
      "        -3.69280926e-03, -2.71334499e-02,  2.53562699e-03,\n",
      "         4.34097694e-03,  2.97664106e-03, -2.15674564e-02,\n",
      "         3.61558869e-02,  8.08772743e-02, -2.52821594e-02,\n",
      "         5.80498902e-03, -1.07027963e-02, -2.48672143e-02,\n",
      "        -1.44267939e-02,  3.15219909e-02, -1.14869140e-02,\n",
      "         3.30685545e-03,  1.99409481e-02,  4.99841273e-02,\n",
      "        -4.49993610e-02,  7.72894779e-03,  3.11769322e-02,\n",
      "         3.09103224e-02, -7.71678984e-03,  5.84872290e-02,\n",
      "        -5.42056747e-02, -3.33704031e-03, -1.83011349e-02,\n",
      "         1.62854549e-02,  5.31176850e-03, -2.09810529e-02,\n",
      "         4.91806827e-02, -8.42866953e-03, -6.51505729e-03,\n",
      "         1.71760134e-02,  2.72494126e-02, -2.92305984e-02,\n",
      "         4.24528196e-02, -3.60786691e-02,  1.84046254e-02,\n",
      "        -3.13077159e-02,  4.14321199e-02, -5.59886619e-02,\n",
      "         1.49268257e-02,  2.60685254e-02, -5.52150421e-02,\n",
      "         1.29697798e-03, -4.77617718e-02,  3.62244174e-02,\n",
      "         2.06457376e-02, -4.58857678e-02, -5.30554503e-02,\n",
      "        -3.68059464e-02,  1.84508283e-02,  3.81463915e-02,\n",
      "         4.55434341e-03, -5.33704786e-03, -3.57671385e-03,\n",
      "         2.03389544e-02,  5.48691452e-02, -7.58882030e-04,\n",
      "         2.84435395e-02,  4.83720340e-02, -2.99586020e-02,\n",
      "        -1.76797677e-02,  3.35277468e-02,  1.37342792e-03,\n",
      "        -2.68641692e-02,  2.64775194e-03, -9.99408774e-03,\n",
      "        -1.80058938e-04,  1.16342120e-03,  8.49529207e-02,\n",
      "        -2.98755262e-02, -6.69693947e-02,  4.05759141e-02,\n",
      "        -3.55412103e-02, -1.86089706e-03,  5.91269287e-04,\n",
      "         1.39302425e-02, -2.47889962e-02,  2.53034607e-02,\n",
      "        -3.97712365e-02,  2.88634356e-02, -9.16614607e-02,\n",
      "         5.57092857e-03, -9.73220728e-03, -1.74500048e-02,\n",
      "        -8.68848637e-02, -1.21405171e-02,  3.64730810e-03,\n",
      "         2.25705188e-02,  7.20277280e-02,  1.51512539e-02,\n",
      "        -6.49104416e-02,  2.41179708e-02, -2.87707220e-03,\n",
      "         6.93614548e-03,  9.34235081e-02,  6.99082762e-03,\n",
      "         2.98845358e-02, -2.84019560e-02, -4.98192245e-03,\n",
      "         4.62821871e-02,  1.75464898e-02, -1.25577953e-02,\n",
      "        -1.54062669e-04, -2.99329329e-02,  5.02549997e-03,\n",
      "         1.33744460e-02,  2.94565596e-02, -3.77633646e-02,\n",
      "        -8.40126351e-02,  7.31298653e-03, -2.28878614e-02,\n",
      "         2.03754026e-02,  5.52985556e-02, -3.43565531e-02,\n",
      "        -3.25125130e-03,  5.76067120e-02, -2.09484603e-02,\n",
      "        -4.34193350e-02, -3.39921862e-02,  3.61151509e-02,\n",
      "        -3.49004455e-02, -1.85734071e-02, -6.32531056e-03,\n",
      "         2.01485047e-04, -5.39695248e-02, -2.90979408e-02,\n",
      "         1.02022663e-02,  1.68841742e-02, -5.24550723e-03,\n",
      "        -5.14518142e-05,  1.77873112e-03, -5.52265123e-02,\n",
      "        -1.83010604e-02,  9.57900565e-03,  2.36210283e-02,\n",
      "        -2.14605872e-02, -1.41496910e-02, -2.18637604e-02,\n",
      "        -2.91407406e-02,  4.97647040e-02,  5.00695221e-03,\n",
      "         4.45472971e-02, -2.88760737e-02,  4.47045900e-02,\n",
      "         1.29674915e-02, -9.22137685e-03, -5.52491844e-02,\n",
      "        -3.51047032e-02,  4.67591695e-02, -3.55606750e-02]]), 'documents': ['Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans using natural language. The ultimate goal of NLP is to enable machines to understand, interpret, and generate human language in a way that is both meaningful and useful. NLP combines computational linguistics, machine learning, and deep learning to process and analyze large amounts of natural language data'], 'uris': None, 'data': None, 'metadatas': [None], 'included': [<IncludeEnum.embeddings: 'embeddings'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Documents in DB: \", db.count())\n",
    "print(\"The First Documents is: \", db.peek(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66656fd1",
   "metadata": {
    "papermill": {
     "duration": 0.004018,
     "end_time": "2024-12-07T18:44:02.604575",
     "exception": false,
     "start_time": "2024-12-07T18:44:02.600557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdc5228e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T18:44:02.614737Z",
     "iopub.status.busy": "2024-12-07T18:44:02.614358Z",
     "iopub.status.idle": "2024-12-07T18:44:03.573304Z",
     "shell.execute_reply": "2024-12-07T18:44:03.572021Z"
    },
    "papermill": {
     "duration": 0.966746,
     "end_time": "2024-12-07T18:44:03.575702",
     "exception": false,
     "start_time": "2024-12-07T18:44:02.608956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  {'ids': [['5']], 'embeddings': None, 'documents': [['Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation. Unlike traditional one-hot encoding, word embeddings use dense vectors of real numbers that capture semantic relationships between words. Popular word embedding models include Word2Vec, GloVe, and FastText, all of which are used to learn word representations from large text corpora.']], 'uris': None, 'data': None, 'metadatas': [[None]], 'distances': [[0.2926563024520874]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
      "###############\n",
      "Documents Retrived:  [['Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation. Unlike traditional one-hot encoding, word embeddings use dense vectors of real numbers that capture semantic relationships between words. Popular word embedding models include Word2Vec, GloVe, and FastText, all of which are used to learn word representations from large text corpora.']]\n",
      "###############\n",
      "[['Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation. Unlike traditional one-hot encoding, word embeddings use dense vectors of real numbers that capture semantic relationships between words. Popular word embedding models include Word2Vec, GloVe, and FastText, all of which are used to learn word representations from large text corpora.']]\n"
     ]
    }
   ],
   "source": [
    "embed_fun.document_mode = True \n",
    "query = \"How does word embedding helps us?\"\n",
    "result = db.query(query_texts = [query], n_results = 1)\n",
    "print(\"Result: \", result)\n",
    "print(\"###############\")\n",
    "print(\"Documents Retrived: \", result[\"documents\"])\n",
    "print(\"###############\")\n",
    "[[passage]] = result[\"documents\"]\n",
    "print([[passage]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2dc1bc",
   "metadata": {
    "papermill": {
     "duration": 0.003874,
     "end_time": "2024-12-07T18:44:03.583866",
     "exception": false,
     "start_time": "2024-12-07T18:44:03.579992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2febfbef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T18:44:03.594174Z",
     "iopub.status.busy": "2024-12-07T18:44:03.593730Z",
     "iopub.status.idle": "2024-12-07T18:44:03.600841Z",
     "shell.execute_reply": "2024-12-07T18:44:03.599828Z"
    },
    "papermill": {
     "duration": 0.015163,
     "end_time": "2024-12-07T18:44:03.603338",
     "exception": false,
     "start_time": "2024-12-07T18:44:03.588175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passage:  Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation. Unlike traditional one-hot encoding, word embeddings use dense vectors of real numbers that capture semantic relationships between words. Popular word embedding models include Word2Vec, GloVe, and FastText, all of which are used to learn word representations from large text corpora.\n",
      "query:  How does word embedding helps us?\n",
      "################\n",
      "You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
      "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
      "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
      "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
      "\n",
      "QUESTION: How does word embedding helps us?\n",
      "PASSAGE: Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation. Unlike traditional one-hot encoding, word embeddings use dense vectors of real numbers that capture semantic relationships between words. Popular word embedding models include Word2Vec, GloVe, and FastText, all of which are used to learn word representations from large text corpora.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"passage: \", passage.replace(\"\\n\", \" \"))\n",
    "print(\"query: \", query.replace(\"\\n\", \" \"))\n",
    "print(\"################\")\n",
    "passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "query_oneline = query.replace(\"\\n\", \" \")\n",
    "prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
    "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
    "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
    "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
    "\n",
    "QUESTION: {query_oneline}\n",
    "PASSAGE: {passage_oneline}\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d3381d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T18:44:03.613380Z",
     "iopub.status.busy": "2024-12-07T18:44:03.612975Z",
     "iopub.status.idle": "2024-12-07T18:44:05.892059Z",
     "shell.execute_reply": "2024-12-07T18:44:05.890979Z"
    },
    "papermill": {
     "duration": 2.286965,
     "end_time": "2024-12-07T18:44:05.894513",
     "exception": false,
     "start_time": "2024-12-07T18:44:03.607548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Word embeddings are a really helpful way to represent words in a way that computers can understand.  Imagine you want a computer to understand that \\\"happy\\\" and \\\"joyful\\\" are similar words.  Instead of just treating them as completely separate, word embeddings give each word a kind of \\\"fingerprint\\\" \\u2013 a set of numbers \\u2013 and words with similar meanings have similar fingerprints. This lets computers understand the relationships between words better, which is crucial for many tasks like machine translation and text analysis, because it allows them to capture the nuances of language more effectively than older methods.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.37257245934527855\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 174,\n",
      "        \"candidates_token_count\": 115,\n",
      "        \"total_token_count\": 289\n",
      "      }\n",
      "    }),\n",
      ")\n",
      "Word embeddings are a really helpful way to represent words in a way that computers can understand.  Imagine you want a computer to understand that \"happy\" and \"joyful\" are similar words.  Instead of just treating them as completely separate, word embeddings give each word a kind of \"fingerprint\" – a set of numbers – and words with similar meanings have similar fingerprints. This lets computers understand the relationships between words better, which is crucial for many tasks like machine translation and text analysis, because it allows them to capture the nuances of language more effectively than older methods.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "answer = model.generate_content(prompt)\n",
    "print(\"Answer: \", answer)\n",
    "print(answer.text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.512645,
   "end_time": "2024-12-07T18:44:09.080146",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-07T18:43:19.567501",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
